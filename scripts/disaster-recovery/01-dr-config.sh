#!/bin/bash # Disaster Recovery Configuration Script # This script sets up the disaster recovery environment and configuration set -euo pipefail # Configuration export DR_CONFIG_DIR="/opt/backstage-dr" export DR_BACKUP_DIR="/opt/backstage-dr/backups" export DR_SCRIPTS_DIR="/opt/backstage-dr/scripts" export DR_LOGS_DIR="/opt/backstage-dr/logs" export DR_CONFIG_FILE="/opt/backstage-dr/config/dr-config.yaml" # Primary and DR site configurations export PRIMARY_REGION="us-west-2" export DR_REGION="us-east-1" export PRIMARY_CLUSTER="backstage-primary" export DR_CLUSTER="backstage-dr" # RTO and RPO settings export TARGET_RTO="4h" # 4 hours Recovery Time Objective export TARGET_RPO="1h" # 1 hour Recovery Point Objective export BACKUP_RETENTION="30d" # 30 days backup retention # Database configurations export POSTGRES_PRIMARY_HOST="backstage-db-primary.aws.com" export POSTGRES_DR_HOST="backstage-db-dr.aws.com" export POSTGRES_PORT="5432" export POSTGRES_DB="backstage" # S3 backup configurations export S3_BACKUP_BUCKET="backstage-dr-backups-$(date +%Y)" export S3_BACKUP_PREFIX="backstage" export S3_BACKUP_REGION="${DR_REGION}" # Redis configurations export REDIS_PRIMARY_HOST="backstage-redis-primary.aws.com" export REDIS_DR_HOST="backstage-redis-dr.aws.com" export REDIS_PORT="6379" # Monitoring and alerting export SLACK_WEBHOOK_URL="${SLACK_WEBHOOK_URL:-}" export PAGERDUTY_SERVICE_KEY="${PAGERDUTY_SERVICE_KEY:-}" export EMAIL_ALERTS="${EMAIL_ALERTS:-ops@backstage.local}" # Logging setup setup_logging() { local log_level="${1:-INFO}" export LOG_LEVEL="${log_level}" # Create log directory mkdir -p "${DR_LOGS_DIR}" # Setup log file with rotation export DR_LOG_FILE="${DR_LOGS_DIR}/disaster-recovery-$(date +%Y%m%d).log" # Log function log() { local level="$1" shift echo "[$(date '+%Y-%m-%d %H:%M:%S')] [${level}] $*" | tee -a "${DR_LOG_FILE}" } export -f log } # Initialize DR environment init_dr_environment() { log "INFO" "Initializing disaster recovery environment..." # Create directory structure mkdir -p "${DR_CONFIG_DIR}"/{config,scripts,backups,logs,temp} mkdir -p "${DR_BACKUP_DIR}"/{database,files,kubernetes,certificates} # Set permissions chmod 755 "${DR_CONFIG_DIR}" chmod 750 "${DR_BACKUP_DIR}" chmod 700 "${DR_CONFIG_DIR}/config" # Create DR configuration file cat > "${DR_CONFIG_FILE}" <<EOF # Backstage Disaster Recovery Configuration apiVersion: v1 kind: Config metadata: name: backstage-dr-config version: "1.0" created: "$(date -Iseconds)" # Site configurations sites: primary: region: ${PRIMARY_REGION} cluster: ${PRIMARY_CLUSTER} endpoint: https://backstage.local status: active dr: region: ${DR_REGION} cluster: ${DR_CLUSTER} endpoint: https://dr.backstage.local status: standby # Recovery objectives recovery: rto: ${TARGET_RTO} rpo: ${TARGET_RPO} backup_retention: ${BACKUP_RETENTION} # Database configuration database: engine: postgresql primary: host: ${POSTGRES_PRIMARY_HOST} port: ${POSTGRES_PORT} database: ${POSTGRES_DB} dr: host: ${POSTGRES_DR_HOST} port: ${POSTGRES_PORT} database: ${POSTGRES_DB} backup: method: continuous interval: 15m compression: gzip encryption: true # Cache configuration cache: engine: redis primary: host: ${REDIS_PRIMARY_HOST} port: ${REDIS_PORT} dr: host: ${REDIS_DR_HOST} port: ${REDIS_PORT} backup: method: snapshot interval: 1h # File storage configuration storage: s3: backup_bucket: ${S3_BACKUP_BUCKET} backup_prefix: ${S3_BACKUP_PREFIX} region: ${S3_BACKUP_REGION} lifecycle_policy: ${BACKUP_RETENTION} # Kubernetes configuration kubernetes: primary_context: ${PRIMARY_CLUSTER} dr_context: ${DR_CLUSTER} backup_namespaces: - developer-portal - developer-portal-staging - istio-system exclude_resources: - events - logs - pods # Monitoring configuration monitoring: healthchecks: enabled: true interval: 30s timeout: 10s endpoints: - https://backstage.local/health - https://backstage.local/api/health alerts: slack: webhook: ${SLACK_WEBHOOK_URL} channel: "#ops-alerts" pagerduty: service_key: ${PAGERDUTY_SERVICE_KEY} email: recipients: ${EMAIL_ALERTS} # Automation configuration automation: failover: automatic: false require_confirmation: true max_attempts: 3 failback: automatic: false require_manual_approval: true testing: schedule: "0 2 * * 0" # Weekly Sunday 2 AM retention: 7 EOF log "INFO" "DR configuration file created at ${DR_CONFIG_FILE}" } # Validate DR configuration validate_dr_config() { log "INFO" "Validating disaster recovery configuration..." # Check required tools local required_tools=("kubectl" "aws" "pg_dump" "redis-cli" "jq" "yq") for tool in "${required_tools[@]}"; do if ! command -v "$tool" &> /dev/null; then log "ERROR" "Required tool not found: $tool" exit 1 fi done # Check AWS credentials if ! aws sts get-caller-identity &> /dev/null; then log "ERROR" "AWS credentials not configured" exit 1 fi # Check Kubernetes contexts if ! kubectl config get-contexts "${PRIMARY_CLUSTER}" &> /dev/null; then log "WARNING" "Primary cluster context not found: ${PRIMARY_CLUSTER}" fi if ! kubectl config get-contexts "${DR_CLUSTER}" &> /dev/null; then log "WARNING" "DR cluster context not found: ${DR_CLUSTER}" fi # Check S3 bucket access if ! aws s3 ls "s3://${S3_BACKUP_BUCKET}" &> /dev/null; then log "INFO" "Creating S3 backup bucket: ${S3_BACKUP_BUCKET}" aws s3 mb "s3://${S3_BACKUP_BUCKET}" --region "${S3_BACKUP_REGION}" # Configure bucket lifecycle policy cat > "/tmp/lifecycle-policy.json" <<EOF { "Rules": [ { "ID": "BackupRetentionRule", "Status": "Enabled", "Filter": {"Prefix": "${S3_BACKUP_PREFIX}/"}, "Expiration": {"Days": 30}, "NoncurrentVersionExpiration": {"NoncurrentDays": 7}, "AbortIncompleteMultipartUpload": {"DaysAfterInitiation": 1} } ] } EOF aws s3api put-bucket-lifecycle-configuration \ --bucket "${S3_BACKUP_BUCKET}" \ --lifecycle-configuration file:///tmp/lifecycle-policy.json rm -f "/tmp/lifecycle-policy.json" fi log "INFO" "DR configuration validation completed" } # Setup DR monitoring setup_dr_monitoring() { log "INFO" "Setting up disaster recovery monitoring..." # Create monitoring script cat > "${DR_SCRIPTS_DIR}/monitor-dr.sh" <<'EOF' #!/bin/bash # DR Health Monitoring Script set -euo pipefail source /opt/backstage-dr/scripts/01-dr-config.sh check_primary_health() { local endpoint="$1" local timeout="${2:-10}" if curl -s --max-time "${timeout}" "${endpoint}/health" | jq -e '.status == "ok"' > /dev/null 2>&1; then return 0 else return 1 fi } check_database_health() { local host="$1" local port="$2" local database="$3" if PGPASSWORD="${POSTGRES_PASSWORD}" pg_isready -h "${host}" -p "${port}" -d "${database}" > /dev/null 2>&1; then return 0 else return 1 fi } check_redis_health() { local host="$1" local port="$2" if redis-cli -h "${host}" -p "${port}" ping | grep -q "PONG"; then return 0 else return 1 fi } send_alert() { local message="$1" local severity="${2:-warning}" log "ERROR" "${message}" # Send Slack notification if [[ -n "${SLACK_WEBHOOK_URL}" ]]; then curl -X POST "${SLACK_WEBHOOK_URL}" \ -H 'Content-type: application/json' \ --data "{\"text\":\" Backstage DR Alert (${severity}): ${message}\"}" fi # Send email notification if [[ -n "${EMAIL_ALERTS}" ]] && command -v mail >/dev/null 2>&1; then echo "${message}" | mail -s "Backstage DR Alert - ${severity}" "${EMAIL_ALERTS}" fi } # Main monitoring loop main() { log "INFO" "Starting DR health monitoring..." # Check primary site health if ! check_primary_health "https://backstage.local"; then send_alert "Primary site health check failed" "critical" # Could trigger automatic failover here if configured fi # Check database health if ! check_database_health "${POSTGRES_PRIMARY_HOST}" "${POSTGRES_PORT}" "${POSTGRES_DB}"; then send_alert "Primary database health check failed" "critical" fi if ! check_database_health "${POSTGRES_DR_HOST}" "${POSTGRES_PORT}" "${POSTGRES_DB}"; then send_alert "DR database health check failed" "warning" fi # Check Redis health if ! check_redis_health "${REDIS_PRIMARY_HOST}" "${REDIS_PORT}"; then send_alert "Primary Redis health check failed" "warning" fi if ! check_redis_health "${REDIS_DR_HOST}" "${REDIS_PORT}"; then send_alert "DR Redis health check failed" "warning" fi log "INFO" "DR health monitoring completed" } main "$@" EOF chmod +x "${DR_SCRIPTS_DIR}/monitor-dr.sh" # Create systemd service for monitoring if command -v systemctl >/dev/null 2>&1; then cat > "/etc/systemd/system/backstage-dr-monitor.service" <<EOF [Unit] Description=Backstage Disaster Recovery Monitor After=network.target [Service] Type=simple User=root WorkingDirectory=${DR_SCRIPTS_DIR} ExecStart=${DR_SCRIPTS_DIR}/monitor-dr.sh Restart=always RestartSec=30 [Install] WantedBy=multi-user.target EOF cat > "/etc/systemd/system/backstage-dr-monitor.timer" <<EOF [Unit] Description=Run Backstage DR Monitor every 5 minutes Requires=backstage-dr-monitor.service [Timer] OnBootSec=5min OnUnitActiveSec=5min [Install] WantedBy=timers.target EOF systemctl daemon-reload systemctl enable backstage-dr-monitor.timer systemctl start backstage-dr-monitor.timer log "INFO" "DR monitoring service installed and started" fi } # Create DR management scripts create_dr_scripts() { log "INFO" "Creating disaster recovery management scripts..." # Main DR management script cat > "${DR_SCRIPTS_DIR}/dr-manager.sh" <<'EOF' #!/bin/bash # Disaster Recovery Manager set -euo pipefail source /opt/backstage-dr/scripts/01-dr-config.sh usage() { cat <<EOF Usage: $0 <command> [options] Commands: status Show DR status backup Perform backup restore Restore from backup failover Failover to DR site failback Failback to primary site test Test DR procedures monitor Run health monitoring Options: --dry-run Show what would be done without executing --force Skip confirmations --backup-tag TAG Use specific backup tag --help Show this help message Examples: $0 status $0 backup --dry-run $0 failover --force $0 restore --backup-tag 20231201-120000 EOF } # Show DR status show_status() { log "INFO" "Checking disaster recovery status..." echo "=== Backstage Disaster Recovery Status ===" echo "Timestamp: $(date -Iseconds)" echo "Primary Region: ${PRIMARY_REGION}" echo "DR Region: ${DR_REGION}" echo "" # Check primary site if curl -s --max-time 10 https://backstage.local/health >/dev/null 2>&1; then echo " Primary Site: HEALTHY" else echo " Primary Site: UNHEALTHY" fi # Check DR site if curl -s --max-time 10 https://dr.backstage.local/health >/dev/null 2>&1; then echo " DR Site: HEALTHY" else echo " DR Site: STANDBY/UNHEALTHY" fi # Check databases if PGPASSWORD="${POSTGRES_PASSWORD}" pg_isready -h "${POSTGRES_PRIMARY_HOST}" -p "${POSTGRES_PORT}" >/dev/null 2>&1; then echo " Primary Database: HEALTHY" else echo " Primary Database: UNHEALTHY" fi if PGPASSWORD="${POSTGRES_PASSWORD}" pg_isready -h "${POSTGRES_DR_HOST}" -p "${POSTGRES_PORT}" >/dev/null 2>&1; then echo " DR Database: HEALTHY" else echo " DR Database: UNHEALTHY" fi # Show recent backups echo "" echo "=== Recent Backups ===" aws s3 ls "s3://${S3_BACKUP_BUCKET}/${S3_BACKUP_PREFIX}/" --recursive | tail -10 || echo "No backups found" } # Parse command line arguments COMMAND="" DRY_RUN=false FORCE=false BACKUP_TAG="" while [[ $# -gt 0 ]]; do case $1 in status|backup|restore|failover|failback|test|monitor) COMMAND="$1" shift ;; --dry-run) DRY_RUN=true shift ;; --force) FORCE=true shift ;; --backup-tag) BACKUP_TAG="$2" shift 2 ;; --help) usage exit 0 ;; *) echo "Unknown option: $1" >&2 usage >&2 exit 1 ;; esac done if [[ -z "${COMMAND}" ]]; then echo "Error: Command required" >&2 usage >&2 exit 1 fi # Execute command case "${COMMAND}" in status) show_status ;; backup) /opt/backstage-dr/scripts/02-backup-automation.sh ;; restore) /opt/backstage-dr/scripts/03-restore-automation.sh ${BACKUP_TAG:+--backup-tag "${BACKUP_TAG}"} ;; failover) /opt/backstage-dr/scripts/04-failover-automation.sh ${FORCE:+--force} ;; failback) /opt/backstage-dr/scripts/05-failback-automation.sh ${FORCE:+--force} ;; test) /opt/backstage-dr/scripts/06-dr-testing.sh ;; monitor) /opt/backstage-dr/scripts/monitor-dr.sh ;; *) echo "Unknown command: ${COMMAND}" >&2 exit 1 ;; esac EOF chmod +x "${DR_SCRIPTS_DIR}/dr-manager.sh" # Create symlink for easy access ln -sf "${DR_SCRIPTS_DIR}/dr-manager.sh" "/usr/local/bin/backstage-dr" log "INFO" "DR management scripts created" } # Main execution main() { setup_logging "INFO" log "INFO" "Starting Backstage Disaster Recovery configuration..." init_dr_environment validate_dr_config setup_dr_monitoring create_dr_scripts log "INFO" "Disaster Recovery configuration completed successfully" log "INFO" "Use 'backstage-dr status' to check DR status" log "INFO" "Use 'backstage-dr --help' for available commands" } # Execute main function if script is run directly if [[ "${BASH_SOURCE[0]}" == "${0}" ]]; then main "$@" fi